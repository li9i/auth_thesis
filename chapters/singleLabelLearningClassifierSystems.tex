\chapter{Μανθάνοντα Συστήματα Ταξινομητών για Μονοκατηγορική Ταξινόμηση}
\label{learningClassifierSystems}
Επινοηθέντα το 1975 από τον John Holland \cite{holland}, τα Μανθάνοντα Συστήματα Ταξινομητών (ΜαΣΤ), αποτελούν μια προσέγγιση Μηχανικής Μάθησης Βασισμένη στη Γενετική. Χρησιμοποιούν κανόνες ταξινόμησης για την επίλυση προβλημάτων Μαρκοβιανής Απόφασης και Ταξινόμησης, παρέχοντας μία σειρά αρχών για online μηχανική μάθηση μέσω της προσαρμογής \cite{holland78}.

\section{Γενικό Μοντέλο}
\label{sec:lcsGenericModel}
Η μορφή ενός ΜαΣΤ προσομοιάζει με αυτή ενός ελεγκτή, όπως φαίνεται στο Σχήμα \ref{fig:LCScontroller}.

\begin{figure}[htb]
 \begin{center}
  \input{./images/LCScontroller.tex}
  \caption{Εξωτερική Μορφή Μανθάνοντος Συστήματος Ταξινομητών.}
  \label{fig:LCScontroller}
 \end{center}
\end{figure}

Στα ΜαΣΤ, η μάθηση μοντελοποιείται ως μία διαδικασία online προσαρμογής σε ένα άγνωστο περιβάλλον, το οποίο αντιπροσωπεύει το πρόβλημα, και το οποίο τροφοδοτεί το σύστημα με, συνήθως αριθμητικές, ανταμοιβές. Ένα ΜαΣΤ αντιλαμβάνεται το περιβάλλον του μέσω των ανιχνευτών (detectors) του, και, με βάση τις αισθήσεις του, επιλέγει μία ενέργεια που εφαρμόζεται στο περιβάλλον του μέσω των επενεργητών (effectors) του. Πρακτικά, δέχεται ένα διάνυσμα εισόδου (vision vector) από το περιβάλλον και εξάγει μία απόφαση - δράση προς αξιολόγηση από το περιβάλλον. Ανάλογα με την αποτελεσματικότητα των ενεργειών του, το περιβάλλον μπορεί να αποδώσει κάποιου είδους ανταμοιβή στο σύστημα, και, συνεπώς, στο πλαίσιο αυτό, ένα ΜαΣΤ προσπαθεί να μάθει μεγιστοποιώντας το ποσό της λαμβανόμενης ανταμοιβής.

Η εσωτερική δομή ενός ΜαΣΤ αποτελείται από ένα σύνολο τμημάτων και συνιστωσών, μέρος του οποίου φαίνεται στο Σχήμα \ref{fig:michiganLcs}. Πιο συγκεκριμένα, ένα ΜαΣΤ αποτελείται από:
\begin{enumerate}
\item Ένα \emph{σύνολο κανόνων ταξινόμησης} $[P]$ που ονομάζεται πληθυσμός. Καθώς ένας κανόνας μπορεί να εμφανίζεται περισσότερο από μία φορά μέσα στον πληθυσμό, μακροσκοπικά, αντιλαμβανόμαστε τη συγχώνευσή τους σε μακρο-κανόνες (macroclassifiers), δηλαδή κανόνες με μία συγκεκριμένη πληθικότητα, ίση με τον αριθμό των επαναλήψεων του δεδομένου κανόνα στον πληθυσμό.

Όπως αναφέραμε και στην Παρ. \ref{subsubsec:ruleBasedClassifiers}, ένας κανόνας ταξινόμησης αποτελείται από δύο τμήματα: το τμήμα συνθήκης και το τμήμα απόφασης. Η \emph{συνθήκη} προσδιορίζει ένα τμήμα του χώρου γνωρισμάτων του προβλήματος, ενώ η \emph{απόφαση} είναι η ενέργεια που σχετίζεται με το υποπρόβλημα που προσδιορίζεται από τη συνθήκη του ίδιου κανόνα. Στα πλαίσια των ΜαΣΤ, εισάγονται διάφορα μεγέθη με τα οποία σχετίζονται οι κανόνες, ανάμεσά τους, η \emph{πρόβλεψη} και η \emph{καταλληλότητα}. Η πρόβλεψη (ή δύναμη) ενός κανόνα είναι υπεύθυνη για την εκτίμηση της αξίας της ενέργειας του κανόνα, από την άποψη των μελλοντικών ανταμοιβών του ΜαΣΤ. Η καταλληλότητα προσφέρει μία εκτίμηση της ποιότητάς του.

\item Ένα \textit{σύνολο ενεργοποίησης} $[M]$ (\emph{match set}) που δημιουργείται από τους κανόνες του $[P]$ που ενεργοποιούνται από (καλύπτουν) το διάνυσμα εισόδου.

\item Ένα σύνολο $[A]$ (\emph{σύνολο ενεργειών - action set}) που αποτελείται από τους κανόνες του $[M]$, των οποίων η απόφαση συνάδει με αυτή που επιλέγει το ΜαΣΤ.

\item Το \emph{Γενετικό Αλγόριθμο}, ως το ένα από τα δύο μέρη της Συνιστώσας Ανακάλυψης, που κατά τη φάση της εξερεύνησης είναι υπεύθυνος για την επιλογή κανόνων με βάση την καταλληλότητά τους, την αντιγραφή τους, την εφαρμογή των γενετικών τελεστών της διασταύρωσης και μετάλλαξης στα προαναφερθέντα αντίγραφα και την υπό συνθήκες αφομοίωση των απογόνων από ήδη υπάρχοντες κανόνες του πληθυσμού. Για την εξέλιξη κανόνων στα ΜαΣΤ έχει επικρατήσει η χρήση Γενετικών Αλγορίθμων Σταθερής Κατάστασης (Εν. \ref{sec:naturalSelectionProcess}), σε συνδυασμό, όπως προείπαμε, με την προσέγγιση Michigan για την αναπαράσταση των χρωμοσωμάτων. Ο συνδυασμός των δύο είναι φυσικός, καθώς επιχειρείται η εύρεση ενός συνόλου συνεργαζόμενων κανόνων.

\item Το \emph{τμήμα Κάλυψης} ως το δεύτερο μέρος της Συνιστώσας Ανακάλυψης. Το τμήμα Κάλυψης παράγει κανόνες όταν δεν υπάρχουν κανόνες στον πληθυσμό που να ενεργοποιούνται για ένα δεδομένο διάνυσμα εισόδου, συνήθως στις πρώτες επαναλήψεις όπου ο πληθυσμός είναι κενός κανόνων.

\item Τη \emph{λειτουργία ομαδοποίησης - αφομοίωσης} (subsumption). Αναλαμβάνει την αφομοίωση απογόνων, μετά τη δημιουργία τους, από κανόνες αρκούντως κατάλληλους και έμπειρους, με τμήμα συνθήκης γενικότερο και τμήμα απόφασης ειδικότερο από τους απογόνους.

\item Τη \emph{λειτουργία διαγραφής κανόνων} που αναλαμβάνει να διατηρήσει κάτω από ένα όριο τον αριθμό των κανόνων του πληθυσμού. Ενεργοποιείται όταν, λόγω συνεχούς παραγωγής κανόνων από το Γενετικό Αλγόριθμο, ο αριθμός των κανόνων του πληθυσμού ξεπεράσει το προαναφερθέν όριο, διαγράφοντας κανόνες με πιθανότητα αντίστροφη της καταλληλότητάς τους.

\item Τη \emph{συνιστώσα ενίσχυσης} ή \emph{απόδοσης ανταμοιβής}. Κατανέμει την εισερχόμενη από το περιβάλλον ανταμοιβή στους κανόνες που είναι υπεύθυνοι για αυτήν και ενημερώνει τις σχετικές με την ποιότητα παραμέτρους τους.

\item Το \emph{τμήμα Επίδοσης}. Μετά το σχηματισμό του $[M]$, το σύστημα καλείται να λάβει μία απόφαση από αυτές που υποστηρίζουν οι κανόνες συνόλου αυτού. Εν γένει, οι ενέργειες που υποστηρίζονται είναι διαφορετικές και, συνεπώς, αντικρουόμενες. Όπως αναφέρθηκε παραπάνω, για κάθε νέα είσοδο, το ΜαΣΤ επιλέγει μία δράση βάσει των αποφάσεων των κανόνων του συνόλου $[M]$. Η επιλογή της δράσης εξαρτάται από τον τρόπο λειτουργίας του συστήματος σε εκείνη τη στιγμή. Εάν βρίσκεται σε φάση \emph{Αξιοποίησης} (exploitation), επιλέγεται η δράση εκείνη που είναι βέλτιστη ως προς κάποια μετρική ή γίνεται ψηφοφορία μεταξύ των κανόνων του $[M]$. Στην περίπτωση που το σύστημα βρίσκεται σε φάση \emph{Εξερεύνησης} (exploration), η επιλογή της δράσης μπορεί να βασίζεται σε κάποια πιθανοτική κατανομή, να είναι τυχαία ή να εναλλάσσεται ανάμεσα σε τυχαία και βέλτιστη. Το ΜαΣΤ, λοιπόν, αξιολογεί κάθε προτεινόμενη ενέργεια από το σύνολο των κανόνων του $[M]$ και με κάποιο προκαθορισμένο τρόπο επιλέγει μία προς εφαρμογή, αποστέλλοντας την στο περιβάλλον, από το οποίο στη συνέχεια περιμένει να λάβει τη βαθμωτή ανταμοιβή.
\end{enumerate}


\begin{figure}[htb]
 \begin{center}
  \input{./images/michiganLcs.tex}
  \caption{Εσωτερική Μορφή ΜαΣΤ τύπου Michigan.}
  \label{fig:michiganLcs}
 \end{center}
\end{figure}


\subsection{Είδη Προβλημάτων}
Τα προβλήματα που καλούνται να λύσουν τα ΜαΣΤ χωρίζονται σε δύο κύριες κατηγορίες: τα προβλήματα \emph{διαδοχικών αποφάσεων} και τα προβλήματα \emph{ενός βήματος}. Για την περιγραφή των προβλημάτων πολλών βημάτων αξιοποιείται η έννοια της Μαρκοβιανής Διαδικασίας Απόφασης και η τεχνική της ενισχυτικής μάθησης με τον αλγόριθμο Q-learning \cite{watkins1989learning}. Αντίθετα, για τα προβλήματα ενός βήματος, όπως είναι η εξόρυξη δεδομένων, η χρήση μεθόδων ενισχυτικής μάθησης δεν είναι απαραίτητη καθώς έχουν αναπτυχθεί ΜαΣΤ που αξιοποιούν μεθόδους επιβλεπόμενης μάθησης \cite{DBLP:series/sci/2008-125}.


\section{ZCS: ΜαΣΤ Βασισμένο στη Δύναμη}
Το πρώτο ολοκληρωμένο ΜαΣΤ ήταν ο ZCS (Zeroth level Classifier System), που δημιουργήθηκε από τον Wilson το 1994 \cite{WilsonZCS}. Κάθε κανόνας του πληθυσμού στον ZCS χαρακτηρίζεται (κυρίως) από μία παράμετρο, τη δύναμή (strength) του, η οποία εκτιμά την ανταμοιβή του κανόνα, και, ταυτόχρονα, ορίζει και την καταλληλότητά του. Ένας κανόνας αναπαρίσταται από την τριάδα $(c, a, s)$ όπου $c$ είναι η συνθήκη του κανόνα, $a$ η προτεινόμενη ενέργεια και $s$ η δύναμή του. Όπως είναι φανερό, για την προσέγγιση της τιμής της δύναμης κάθε κανόνα, χρησιμοποιούνται αλγόριθμοι ενισχυτικής μάθησης. Με την είσοδο του διανύσματος εισόδου, σχηματίζεται το $[M]$ και επιλέγεται κάποια δράση, με τον τρόπο που αναφέρθηκε παραπάνω (Εν. \ref{sec:lcsGenericModel}). Μετά την εκτέλεση της δράσης, η συνιστώσα ενίσχυσης αναλαμβάνει να μοιράσει την ανταμοιβή που λήφθηκε από το σύστημα, η οποία μπορεί να είναι και μηδενική, στους κανόνες του $[M]$ των οποίων η απόφαση συμφωνεί με αυτήν που επέλεξε το σύστημα (στους κανόνες του $[A]$ δηλαδή). Ο Γενετικός Αλγόριθμος εκτελείται στο σύνολο των κανόνων $[P]$, επιλέγοντάς τους πιθανοτικά, με πιθανότητα επιλογής ανάλογη της καταλληλότητας (δύναμής) τους.

Η προσέγγιση του ZCS εξελίσσει κανόνες που είναι \emph{συνεπώς σωστοί} στην πρόβλεψη της προσβλεπόμενης ανταμοιβής, χαράσσοντας ένα \emph{Χάρτη Βέλτιστων Αποφάσεων (ΧΒΑ)}, καθώς η καταλληλότητα ενός ατόμου είναι ευθέως ανάλογη της εκτιμώμενης του ανταμοιβής. Εν γένει, στην ουσία, ένας ΧΒΑ περιέχει τους κανόνες εκείνους οι οποίοι προβλέπουν τη σωστή κλάση για κάθε δείγμα που καλύπτουν.

Για πολλές εφαρμογές, η εξέλιξη ενός ΧΒΑ είναι πλήρως αποδεκτή και, επιπρόσθετα, έχει το πλεονέκτημα της εξέλιξης συνόλων κανόνων πολύ μικρότερων από έναν \emph{Πλήρη Χάρτη Αποφάσεων (ΠΧΑ)} και, συνεπώς, της εξαγωγής λύσεων πιο εύκολων στην ερμηνεία. Ένας ΠΧΑ περιλαμβάνει όλους τους \emph{συνεπώς ακριβείς κανόνες}, ανεξάρτητα από το αν παρέχουν σωστές προβλέψεις ή όχι και, επομένως, ένας ΠΧΑ δεν περιλαμβάνει μόνο όλους τους συνεπώς σωστούς κανόνες, αλλά και όλους τους \emph{συνεπώς λανθασμένους κανόνες}, οι οποίοι παρέχουν λανθασμένες προβλέψεις για κάθε δείγμα που καλύπτουν.

Παρ' όλα αυτά, όπως σημειώνει ο Wilson \cite{XCS}, η επιλογή κανόνων βάσει της δύναμής τους μπορεί να οδηγήσει τον ZCS σε πρόωρη σύγκλιση σε υπό-βέλτιστες λύσεις, προτού καταφέρει να εξερευνήσει πλήρως το χώρο αναζήτησης. Επιπρόσθετα, η βασισμένη-στη-δύναμη επιλογή κανόνων ενδέχεται να δημιουργήσει προβλήματα στην εξερεύνηση, παρουσία αρχικών λύσεων υψηλής καταλληλότητας. Ένα ακόμα ζήτημα που απορρέει από αυτή την αρχιτεκτονική είναι η παραγωγή κανόνων μηδενικού οφέλους για το σύστημα. Αυτό οφείλεται στο γεγονός ότι ο Γενετικός Αλγόριθμος επιλέγει άτομα προς αναπαραγωγή από το σύνολο των διαθέσιμων κανόνων (panmictic selection), με αποτέλεσμα οι γονείς πιθανώς να διαφέρουν ριζικά στις αποφάσεις τους. Τα παραπάνω μειονεκτήματα, σε συνδυασμό με ορισμένες συνθήκες (π.χ δυναμικά περιβάλλοντα ή περιβάλλοντα με ισχυρή παρουσία θορύβου) και η ανάγκη για εξυπηρέτηση των ιδιαίτερων περιορισμών που επιβάλλουν ορισμένες εφαρμογές (η Εξόρυξη Δεδομένων είναι η κυριότερη), οδήγησαν τον Wilson στο συμπέρασμα ότι η εξέλιξη ενός ΠΧΑ ίσως είναι προτιμότερη, σχεδιάζοντας τον XCS.

\section{XCS: ΜαΣΤ Βασισμένο στην Ακρίβεια Πρόβλεψης} 
Ο XCS\footnote{Μια πληρέστερη αλγοριθμική περιγραφή του XCS περιέχεται στο \cite{butzXCS}.} ήταν το πρώτο ΜαΣΤ \cite{XCS} για το οποίο αναφέρθηκαν ακριβείς και βέλτιστες (maximal) γενικεύσεις. Η ικανότητά του αυτή οφείλεται, αφενός, στην αντικατάσταση της βάσης της καταλληλότητας, από τη δύναμη στην ακρίβεια πρόβλεψης, αφετέρου στη μεταβολή του συνόλου από όπου γίνεται επιλογή γονέων από το Γενετικό Αλγόριθμο, από τον πληθυσμό $[P]$, στο σύνολο ενεργειών $[A]$. Με άλλα λόγια, το σύστημα, πλέον, εξελίσσει εκείνους τους κανόνες που είναι οι πλέον ακριβείς στην πρόβλεψη της αναμενόμενης ανταμοιβής και που είναι υπεύθυνοι για τις προσφάτως εφαρμοσθείσες ενέργειες. Κάθε κανόνας αντιπροσωπεύεται πλήρως από την πεντάδα $(c, a, p, \epsilon, F)$ όπου $c$ είναι η συνθήκη του κανόνα, $a$ η ενέργεια που υποστηρίζει, $p$ το ποσό της προβλεπόμενης ανταμοιβής, $\epsilon$ το σφάλμα πρόβλεψης, και $F$ η καταλληλότητά του, η οποία πρέπει να ξανατονίσουμε ότι υπολογίζεται ως συνάρτηση της \emph{ακρίβειας πρόβλεψης} και όχι του μεγέθους της αριθμητικής πρόβλεψης.


Η εξέλιξη ακριβών γενικεύσεων είναι ένα καίριο ζήτημα στα προβλήματα κατηγοριοποίησης, το οποίο θα μας απασχολήσει αργότερα, καθώς το εξαγόμενο μοντέλο θα πρέπει να είναι σε θέση να κατηγοριοποιήσει, όσο το δυνατόν ακριβέστερα, σύνολα δεδομένων με τα οποία δεν έχει εκπαιδευτεί, και, συνεπώς, του είναι πλήρως άγνωστα. Όσο πιο γενικό είναι το μοντέλο, τόσο περισσότερο εξασφαλίζεται ότι θα υπάρχουν κανόνες που θα ενεργοποιούνται για 
κάποιο τυχαίο δείγμα $s$. Από την άλλη, όσο περισσότερο ακριβείς είναι οι κανόνες, τόσο αποτελεσματικότερα θα κατηγοριοποιήσουν το δείγμα, καθιστώντας το μοντέλο αξιόπιστο.


Λόγω ακριβώς της μεταστροφής του υπολογισμού της καταλληλότητας από τη δύναμη στην ακρίβεια πρόβλεψης, ο XCS εξελίσσει ΠΧΑ, δηλαδή \emph{συνεπώς ακριβείς} κανόνες, ανεξάρτητα της ορθότητας πρόβλεψης. Ένας ΠΧΑ, δηλαδή, περιέχει όχι μόνο τους \emph{συνεπώς ορθούς} κανόνες, αλλά και τους \emph{συνεπώς λανθασμένους}, οι οποίοι προβλέπουν άριστα μία μηδενική ανταμοιβή από το σύστημα. Οι ΠΧΑ απαιτούν εκτενέστερη εξερεύνηση του χώρου αναζήτησης καθώς συμπεριλαμβάνουν περιοχές οι οποίες δεν είναι σημαντικές για το πρόβλημα - στόχο, δηλαδή τις περιοχές όπου βρίσκονται οι συνεπώς λανθασμένοι κανόνες. Το γεγονός αυτό αποδεικνύεται επιβαρυντικό σε προβλήματα κατηγοριοποίησης μεγάλης διαστατικότητας ή/και πολλών κλάσεων. Επιπρόσθετα, το μέγεθος ενός ΠΧΑ μπορεί να είναι έως και $n$ φορές μεγαλύτερο από το μέγεθος ενός ΧΒΑ, για δεδομένο πρόβλημα $n$ κλάσεων, απαιτώντας πολύ μεγαλύτερο μέγεθος πληθυσμού και, συνεπώς, περισσότερους υπολογιστικούς πόρους από την εξέλιξη ενός ΧΒΑ \cite{kovacs00}. Επιπρόσθετα, επειδή το μέγεθος του χάρτη κάλυψης έχει αναγνωριστεί ως παράγοντας πολυπλοκότητας για τα ΜαΣΤ \cite{kovacs01}, η εξέλιξη ενός ΠΧΑ απαιτεί περισσότερες επαναλήψεις εκπαίδευσης και, επομένως, μεγαλύτερους χρόνους εκπαίδευσης. Παρ' όλα αυτά, ο Kovacs \cite{kovacs00} σημειώνει ότι μπορεί να υπάρχουν και πλεονεκτήματα στη διατήρηση των συνεπώς λανθασμένων κανόνων σε ένα χάρτη, καθώς, η ύπαρξη τους μπορεί να αποτρέψει το σύστημα από το να τους ανακαλύψει εκ νέου, βελτιώνοντας έτσι τη διαδικασία εξερεύνησης, ενώ, στη φάση της Αξιοποίησης, αυτοί οι κανόνες μπορούν να αποτελέσουν μία λίστα επιβλαβών επιλογών τις οποίες το σύστημα θα αποφύγει να κάνει.

Συνολικά, δεδομένης της φύσης των προβλημάτων κατηγοριοποίησης ενός βήματος, είναι φανερό ότι, για την παραγωγή μίας αποτελεσματικής γνωστικής αναπαράστασης ενός προβλήματος, μόνο οι συνεπώς ορθοί κανόνες είναι απαραίτητοι. Σε αυτή την κατεύθυνση κινείται η επέκταση του XCS, ο UCS. 



\section{UCS: ΜαΣΤ για προβλήματα Επιβλεπόμενης Μάθησης}
Ο UCS είναι το πρώτο ΜαΣΤ που χρησιμοποιεί αποκλειστικά επιβλεπόμενη μάθηση. Κληρονομεί τις κύριες συνιστώσες του XCS και τις προσαρμόζει στα πλαίσια της επιβλεπόμενης μάθησης. Οι διαφορές με τον XCS είναι ότι $i)$ χρησιμοποιεί ελαφρώς διαφορετικές παραμέτρους και εναλλακτικούς τρόπους για την ενημέρωσή τους, και, $ii)$ δεν χρησιμοποιεί μάθηση χρονικών διαφορών για την ενημέρωση της ακρίβειας των κανόνων, αλλά την εκτιμά απευθείας από το ποσοστό ορθών κατηγοριοποιήσεων τους. Επειδή ακριβώς οι κλάσεις στις οποίες ανήκει το κάθε δείγμα $s \in D$ του συνόλου δεδομένων εκπαίδευσης για ένα πρόβλημα κατηγοριοποίησης είναι εκ των προτέρων γνωστές, ο UCS, αντί για το σύνολο $[A]$, δημιουργεί το σύνολο $[C]$ (Correct Set), στο οποίο περιλαμβάνονται όλοι οι κανόνες των οποίων η απόφαση συμφωνεί με την κλάση του δείγματος $s$, δηλαδή οι κανόνες που ταξινομούν ορθά το $s$. Παράλληλα, σχηματίζει και το $[!C]$ (Incorrect Set), το οποίο προκύπτει από την αφαίρεση του $[C]$ από το $[M]$ ($[!C] = [M] - [C]$), το σύνολο δηλαδή των κανόνων που ταξινομούν λανθασμένα το $s$.

Κάθε κανόνας αντιπροσωπεύεται από το σύνολο παραμέτρων $(c, a, tp, exp, num,$\newline $cs, F)$, όπου 

\begin{itemize}
\item $c$ και $a$ η συνθήκη και η απόφαση του κανόνα αντίστοιχα
\item $tp$ ο αριθμός των σωστών κατηγοριοποιήσεων του κανόνα
\item$exp$ ο συνολικός αριθμός των δειγμάτων που κλήθηκε να κατηγοριοποιήσει, δηλαδή ο αριθμός των $[M]$ στα οποία συμμετείχε ο κανόνας
\item $num$ η πληθικότητα του κανόνα, δηλαδή ο αριθμός των αντιγράφων του, στο σύνολο των κανόνων
\item $cs$ μία εκτίμηση του μέσου μεγέθους των $[C]$ στα οποία συμμετείχε ο κανόνας, και, τέλος, 
\item $F$ η καταλληλότητά του.
\end{itemize}

Η \emph{ακρίβεια} (accuracy) ενός κανόνα $r$ ορίζεται ως το ποσοστό ορθών κατηγοριοποιήσεων του:
\begin{equation}
Accuracy(r) = \frac{tp(r)}{exp(r)} 
\end{equation}
\\
Η \emph{καταλληλότητα} (fitness) κάθε μεμονωμένου κανόνα (micro-classifier) δίνεται από τη σχέση: 
\begin{equation}
F_{micro}(r) = Accuracy(r)^{\nu}
\end{equation}
\\
όπου $\nu$ μία σταθερά επιλεγμένη από το χρήστη που καθορίζει το βαθμό πίεσης προς ορθούς κανόνες, με συνηθισμένη τιμή το $10$. Η συνολική καταλληλότητα ενός κανόνα (macro-classifier) προκύπτει από το άθροισμα των καταλληλοτήτων των αντιγράφων του:

\begin{equation}
F_{macro}(r) = num(r) \cdot F_{micro}(r)
\end{equation}
\\
Μετά την παρουσίαση ενός δείγματος $s \in D$ στο σύστημα, σχηματίζεται το $[M]$ και αυξάνεται κατά μία μονάδα η εμπειρία των κανόνων που συμμετέχουν σε αυτό. Στη συνέχεια, σχηματίζεται το $[C]$ από τους κανόνες των οποίων η συνθήκη συμφωνεί με την κλάση του $s$. Για αυτούς τους κανόνες, αυξάνεται κατά ένα ο αριθμός των ορθών κατηγοριοποιήσεων $tp$ υπολογίζεται το μέγεθος $cs$ και ενημερώνεται η καταλληλότητά τους.

Στον UCS, το σύνολο από όπου αντλεί ο Γενετικός Αλγόριθμος τους υποψήφιους γονείς είναι το $[C]$, δηλαδή το σύνολο των κανόνων που ταξινομούν ορθά ένα δεδομένο δείγμα εισόδου. Σε συνδυασμό μάλιστα με τη λειτουργία της διαγραφής που φροντίζει για την απομάκρυνση από τον πληθυσμό κανόνων, επιλέγοντάς τους βάσει της αντίστροφης καταλληλότητάς τους, καταλαβαίνουμε πως ο UCS εξελίσσει ΧΒΑ, χαρτογραφώντας μόνο εκείνες τους κανόνες που προβλέπουν ορθά την κλάση των δειγμάτων που καλύπτουν. Η μεθοδολογία διαγραφής περιλαμβάνει την ανάθεση σε κανόνες του πληθυσμού μίας πιθανότητας διαγραφής ανάλογη προς την ποσότητα \\

\begin{equation}
\label{eq:aslcsDeletion}
d(i) = \left\{
\begin{array}{ c l }
\displaystyle\frac{cs(i) \cdot F_{P}}{F_{micro}(i)}, & experience(i) > \theta_{del} $ και $F_{micro}(i) < \delta \cdot F_{P}
\\
\\

\displaystyle cs(i), & $αλλού$
\end{array}
\right.
\end{equation}
\\
όπου $F_{P}$ είναι το άθροισμα των καταλληλοτήτων των κανόνων του πληθυσμού $[P]$. 

Ο αναγνώστης μπορεί να ανατρέξει στα \cite{bernado2003, orriols2008revisiting} για περισσότερες λεπτομέρειες σχετικά με τον UCS.

\section{*S-LCS: Γενικευμένα ΜαΣΤ για Εξόρυξη Δεδομένων}
Το *S-LCS αποτελεί ένα γενικότερο πλαίσιο επιβλεπόμενης μάθησης με ΜαΣΤ \cite{tzima12} για προβλήματα ενός βήματος και είναι ανεξάρτητο από τον υπολογισμό του τρόπου υπολογισμού της καταλληλότητας. Κληρονομεί το σύνολο των παραμέτρων. λειτουργιών, συνόλων και συνιστωσών του UCS και το επεκτείνει, χρησιμοποιώντας, εκτός από τον αριθμό των ορθών αποφάσεων ενός κανόνα $tp$ και τον αριθμό των λανθασμένων αποφάσεών του $fp$, μία βαθμωτή ποσότητα $str$ που εκτιμά τη μέση ανταμοιβή που λαμβάνει ανά βήμα και τη \emph{χρονοσφραγίδα ts} (timestamp) που αποθηκεύει το χρονικό βήμα της τελευταίας συμμετοχής του σε σύνολο $[C]$. 

Το τμήμα ενημέρωσης κληρονομείται και αυτό από τον UCS, αναλαμβάνοντας να ενημερώσει τις παραμέτρους των κανόνων στα $[M]$, όπως ακριβώς και ο UCS, με την προσθήκη της αύξησης του $fp$ κατά ένα για τους κανόνες που ανήκουν στο $[!C]$. Το τμήμα εξερεύνησης περιλαμβάνει, εκτός από τη λειτουργία της κάλυψης, έναν Γενετικό Αλγόριθμο Σταθερής Κατάστασης, που εφαρμόζεται στα $[C]$ με μέσο ρυθμό $\theta_{GA}$. Όταν ο μέσος όρος των χρονοσφραγίδων των κανόνων ενός $[C]$ ξεπερνά την τρέχουσα τιμή χρονικού βήματος κατά $\theta_{GA}$, τότε εφαρμόζεται ο Γενετικός Αλγόριθμος, επιλέγοντας γονείς με επιλογή τουρνουά. Η διαγραφή των κανόνων γίνεται, όπως και στον UCS, από το σύνολο των κανόνων του πληθυσμού, όταν αυτό ξεπερνάει κάποιο προκαθορισμένο μέγεθος, με ίδια μεθοδολογία ως προς τον UCS.

O *S-LCS διαθέτει δύο εκδόσεις: μία ακριβειο-κεντρική, τον AS-LCS, και μία δυναμο-κεντρική, τον SS-LCS. Ο AS-LCS, εκτός από τις παραπάνω αλλαγές, κληρονομεί αυτούσιες τις λειτουργίες του UCS. Ο SS-LCS προσπαθεί να προσεγγίσει το πρόβλημα της κατηγοριοποίησης με μία πιο παραδοσιακή μέθοδο, κάνοντας χρήση της δύναμης $str$ η οποία χαρακτηρίζει τον κάθε κανόνα. Τα αποτελέσματα του SS-LCS πάνω σε πραγματικά σύνολα δεδομένων δείχνουν πως είναι τουλάχιστον ισοδύναμος, αν όχι καλύτερος, από αρκετές state-of-the-art προσεγγίσεις, παρέχοντας μοντέλα που ισορροπούν τις δύο απαιτήσεις σχεδίασής του: την αποδοτικότητα και την ερμηνευσιμότητα των παραγόμενων μοντέλων.


